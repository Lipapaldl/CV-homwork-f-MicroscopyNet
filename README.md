Dataset:https://www.kaggle.com/datasets/joebeachcapital/defungi

Abstract
This paper presents a novel model,MicroscopyNet, which
reconstructs the baseline model by pre-training the ResNet18
network and loading the attention module. The model introduces a focused linear attention module, which achieves
significant accuracy and inference improvements. With this
approach, we successfully apply the novel structure to residual neural networks, providing an efficient solution for the task of microscopic fungal image recognition. The article
concludes with a comparison of different benchmark models
and an interpretable description of the classification results
using t-SNE dimensionality reduction to highlight the superiority of MicroscopyNet.





@InProceedings{han2023flatten,
  title={FLatten Transformer: Vision Transformer using Focused Linear Attention},
  author={Han, Dongchen and Pan, Xuran and Han, Yizeng and Song, Shiji and Huang, Gao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2023}
}
